## 安装docker

部署网络

```
docker network create doj
```

## MySQL

```bash
mkdir -p mysql/{data,conf,init}

docker run -d \
  --name mysql \
  -p 3306:3306 \
  -e TZ=Asia/Shanghai \
  -e MYSQL_ROOT_PASSWORD=123 \
  -v $(pwd)/mysql/data:/var/lib/mysql \
  -v $(pwd)/mysql/conf:/etc/mysql/conf.d \
  -v $(pwd)/mysql/init:/docker-entrypoint-initdb.d \
  --network doj\
  mysql
```

## nacos

首先得在上面创建的mysql数据库中新建一个nacos表

```sql
create database nacos;
```

然后初始化一下待会要使用的表（参考`SQL/nacos.sql`）。

接着再配置一下nacos的一些参数文件

```bash
mkdir nacos/custom.env

PREFER_HOST_MODE=hostname
MODE=standalone
SPRING_DATASOURCE_PLATFORM=mysql
MYSQL_SERVICE_HOST=172.18.0.2
MYSQL_SERVICE_DB_NAME=nacos
MYSQL_SERVICE_PORT=3306
MYSQL_SERVICE_USER=root
MYSQL_SERVICE_PASSWORD=123
MYSQL_SERVICE_DB_PARAM=characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&allowPublicKeyRetrieval=true&queryTimeout=2400&serverTimezone=Asia/Shanghai
```

简单介绍一下上面这些参数：

```properties
//直译：首选主机模式
PREFER_HOST_MODE=hostname
//使用模式单机模式
MODE=standalone
//直译过来是spring数据源平台（由于我们用的是mysql所以不用改）
SPRING_DATASOURCE_PLATFORM=mysql
//mysql链接参数
MYSQL_SERVICE_DB_PARAM=characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&allowPublicKeyRetrieval=true&queryTimeout=2400&serverTimezone=Asia/Shanghai
//mysql主机地址
MYSQL_SERVICE_HOST=mysql
//mysql数据库名
MYSQL_SERVICE_DB_NAME=nacos
//mysql端口
MYSQL_SERVICE_PORT=3306
//mysql用户名
MYSQL_SERVICE_USER=root
//mysql密码
MYSQL_SERVICE_PASSWORD=123
```

就是上面的`IPAddress`

最后按照下面的命令运行，要注意设置`--network doj`

即确保nacos可以访问到mysql（放在docker中同一个网络下）

```bash
docker run -d \
    --name nacos \
    --env-file ./nacos/custom.env \
    -p 8848:8848 \
    -p 9848:9848 \
    -p 9849:9849 \
    --network doj\
    nacos/nacos-server:v2.5.1-slim
```

## Redis

为了支持长短令牌认证和分布式缓存，项目需要 Redis 服务。

1.  **创建本地目录和配置文件**

    ```sh
    # 创建用于挂载数据和配置的目录
    mkdir -p redis/data
    # 创建一个基础的配置文件
    touch redis/redis.conf
    ```
    在 `redis/redis.conf` 中可以添加自定义配置，例如 `bind 0.0.0.0`。

2.  **运行 Redis 容器**

    ```sh
    docker run -d \
      --name redis \
      -p 6379:6379 \
      -v ${PWD}/redis/data:/data \
      -v ${PWD}/redis/redis.conf:/usr/local/etc/redis/redis.conf \
      --network doj \
      redis:alpine redis-server /usr/local/etc/redis/redis.conf
    ```

    **命令解释**:
    *   `redis:alpine`: 使用基于 Alpine Linux 的轻量级 Redis 镜像。
    *   `-v ${PWD}/redis/data:/data`: 将主机当前目录下的 `redis/data` 文件夹挂载到容器内的 `/data` 目录，用于持久化存储 Redis 数据。
    *   `-v ${PWD}/redis/redis.conf:/usr/local/etc/redis/redis.conf`: 将我们本地的配置文件挂载到容器内对应的位置。
    *   `redis-server /usr/local/etc/redis/redis.conf`: 容器启动时，使用我们指定的配置文件来启动 Redis 服务。

## RabbitMQ (消息队列)

为了实现服务间的异步通信和解耦（例如，判题结果的更新），项目引入了 RabbitMQ。

```sh
docker run -d \
  --name rabbitmq \
  -p 5672:5672 \
  -p 15672:15672 \
  --hostname my-rabbit \
  --network doj \
  rabbitmq:3-management
```

**命令解释**:
*   `rabbitmq:3-management`: 使用包含 Web 管理界面的官方镜像。
*   `-p 5672:5672`: 映射 AMQP 协议端口，供后端服务连接。
*   `-p 15672:15672`: 映射 Web 管理后台端口。您可以通过 `http://localhost:15672` 访问它（默认用户名/密码: `guest`/`guest`）。

## Elasticsearch (ES) 和 Kibana

Elasticsearch 作为核心的搜索引擎，Kibana 提供数据可视化界面。由于我们需要中文分词功能，因此需要构建一个包含 IK 分词插件的自定义 Elasticsearch 镜像。

1.  **创建数据目录**:
    ```sh
    mkdir -p ./elasticsearch/data
    ```

2.  **构建带 IK 分词器的 Elasticsearch 镜像**:
    首先，在项目根目录下创建一个 `Dockerfile` 文件:
    
    ```dockerfile
    # 使用官方 Elasticsearch 7.17.6 作为基础镜像
    FROM elasticsearch:7.17.6
    
    # 安装 IK 分词器插件（指定版本一致）
    RUN bin/elasticsearch-plugin install --batch https://release.infinilabs.com/analysis-ik/stable/elasticsearch-analysis-ik-7.17.6.zip
    
    # 关闭安全认证 + 启动为单节点
    ENV discovery.type=single-node
    ENV xpack.security.enabled=false
    ENV xpack.ml.enabled=false
    ENV xpack.watcher.enabled=false
    ENV xpack.license.self_generated.type=basic
    
    # 暴露端口
    EXPOSE 9200 9300
    
    # 保持默认的 Elasticsearch 启动命令
    ```
    
    然后，在包含此 `Dockerfile` 的目录下执行构建命令：
    ```sh
    docker build -t elasticsearch-with-ik:7.17.6 .
    ```
    
3.  **启动 Elasticsearch (使用自定义镜像)**:
    ```sh
    docker run -d --name elasticsearch \
      -p 9200:9200 -p 9300:9300 \
      --memory="1g" \
      -v $(pwd)/elasticsearch/data:/usr/share/elasticsearch/data \
      --network doj \
      elasticsearch-with-ik:7.17.6
    ```
    -   `--memory=1g`: 限制 ES 内存使用，避免 OOM。
    
4.  **启动 Kibana**:
    ```sh
    docker run -d --name kibana -p 5601:5601 \
      -e "ELASTICSEARCH_HOSTS=http://elasticsearch:9200" \
      --network doj \
      kibana:7.17.6
    ```
    -   `ELASTICSEARCH_HOSTS`: 指向 Elasticsearch 服务名和端口。

## Sentinel (流量治理)

项目使用 Sentinel 进行流量控制和熔断降级。

```sh
docker run -d \
  --name sentinel \
  -p 8858:8858 \
  --network doj \
  bladex/sentinel-dashboard
```

**注意**: Sentinel Dashboard 默认端口为 `8080`，与我们的网关冲突。因此，这里将其映射到主机的 `8858` 端口。

部署成功后，访问 `http://localhost:8858` 进入管理后台 (默认用户名/密码: `sentinel`/`sentinel`)。

## 配置写入

然后按照上面的配置依次修改每个微服务项目中的配置文件

第一个：application.yaml

```yaml
server:
    port: ${doj.port.user-service}
doj:
    db:
        host: 127.0.0.1
        name: doj_user
        user: root
        pwd: 123
    swagger:
        title: 用户服务接口文档
        scan: com.decade.doj.user.controller
```

第二个：bootstrap.yaml

```yaml
spring:
    application:
        name: user-service
    profiles:
        active: dev, common
    cloud:
        nacos:
            server-addr: 127.0.0.1:8848
            config:
                file-extension: yaml
                shared-configs:
                    - dataId: shared-jdbc.yaml
                    - dataId: shared-swagger.yaml
                    - dataId: shared-jwt.yaml
                    - dataId: shared-rabbitmq.yaml
```

然后还有四个在nacos中共享的配置文件

- shared-jdbc.yaml

```yaml
spring:
    datasource:
        driver-class-name: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://${doj.db.host:127.0.0.1}:3306/${doj.db.name}
        username: ${doj.db.user:root}
        password: ${doj.db.pwd:123}
  redis:
    host: ${doj.redis.host:localhost}
    port: 6379

mybatis-plus:
    global-config:
        db-config:
            update-strategy: not_null
            id-type: auto
```

- shared-swagger.yaml

```yaml
logging:
    level:
        com.decade: debug
    pattern:
        dateformat: HH:mm:ss:SSS
knife4j:
    enable: true
    openapi:
        title: ${doj.swagger.title}
        description: "Duck Online Judge API"
        email: "decade-qzj@foxmail.com"
        version: v1.0.0
        group:
            default:
                group-name: default
                api-rule: package
                api-rule-resources:
                    - ${doj.swagger.scan}
```

- shared-jwt.yaml

```yaml
doj:
    jwt:
        location: classpath:doj.jks
        alias: decade
        password: doj123
        tokenTTL: 30m
        refreshTokenTTL: 7d
        authorization: "authorization"
        secret-key: "uid"
```


-   shared-rabbitmq.yaml

```yaml
spring:
    rabbitmq:
        host: ${doj.mq.host:127.0.0.1}
        port: 5672
        username: guest
        password: guest
```