# D-OnlineJudge: 构建与开发指南

本文档为开发者提供一份清晰的指南，说明如何配置开发环境、构建和运行 D-OnlineJudge 项目的后端服务。

---

## 1. 环境准备 (Prerequisites)

在开始之前，请确保您的开发环境中已安装以下软件：

- **JDK**: 版本 `17` 或更高。请通过 `java --version` 命令确认。
- **Maven**: 版本 `3.6` 或更高，用于构建项目。请通过 `mvn --version` 确认。
- **Docker**: 用于运行 MySQL、Nacos 等依赖服务，以及作为代码沙箱的执行环境。
- **Docker Compose**: 用于编排和一键启动多个 Docker 容器。
- **Git**: 用于克隆项目代码。

---

## 2. 部署核心依赖服务

我们使用 Docker 和 Docker Compose 来快速部署项目所需的核心依赖：MySQL 和 Nacos。所有操作都在项目根目录 `/Users/qzj/Desktop/Development/D-OnlineJudge` 下进行。

### 2.1. 创建 Docker 网络

为了让所有容器能够方便地互相通信，首先创建一个专用的 Docker 网络。

```sh
docker network create doj
```

### 2.2. 部署 MySQL

1.  **创建本地目录**：用于持久化存储 MySQL 数据。

    ```sh
    mkdir -p mysql/{data,conf,init}
    ```

2.  **运行 MySQL 容器**：

    ```shdocker run -d \
    docker run -d \
      --name mysql \
      -p 3306:3306 \
      -e TZ=Asia/Shanghai \
      -e MYSQL_ROOT_PASSWORD=123 \
      -v ${PWD}/mysql/data:/var/lib/mysql \
      -v ${PWD}/mysql/conf:/etc/mysql/conf.d \
      -v ${PWD}/mysql/init:/docker-entrypoint-initdb.d \
      --network doj \
      mysql
    ```

3.  **初始化数据库**：进入 MySQL 容器并创建项目所需的数据库。

    ```sh
    # 进入容器的 bash
    docker exec -it mysql bash
    
    # 登录 MySQL
    mysql -uroot -p123
    
    # 在 MySQL 命令行中执行以下 SQL
    CREATE DATABASE doj_user;
    CREATE DATABASE doj_problem;
    CREATE DATABASE doj_submission;
    CREATE DATABASE nacos;
    exit;
    
    # 退出容器
    exit;
    ```

    > **注意**: 更详细的表结构 `CREATE TABLE` 语句位于 `docs/SQL/` 目录和各个服务配置文档中，您可以在需要时手动导入。

### 2.3. 部署 Redis

项目使用 Redis 实现长短令牌存储和分布式缓存。

1.  **创建本地目录与配置文件**

    ```sh
    mkdir -p redis/data
    # (如果不存在) 创建 redis/redis.conf 文件并配置 `bind 0.0.0.0`
    ```

2.  **运行 Redis 容器**

    ```sh
    docker run -d \
      --name redis \
      -p 6379:6379 \
      -v ${PWD}/redis/data:/data \
      -v ${PWD}/redis/redis.conf:/usr/local/etc/redis/redis.conf \
      --network doj \
      redis:alpine redis-server /usr/local/etc/redis/redis.conf
    ```

### 2.2. 部署 Elasticsearch (ES) 和 Kibana

Elasticsearch 作为核心的搜索引擎，Kibana 提供数据可视化界面。由于我们需要中文分词功能，因此需要构建一个包含 IK 分词插件的自定义 Elasticsearch 镜像。

1.  **创建数据目录**:
    ```sh
    mkdir -p ./elasticsearch/data
    ```

2.  **构建带 IK 分词器的 Elasticsearch 镜像**:
    首先，在项目根目录下创建一个 `Dockerfile` 文件（例如，可以放在 `elasticsearch-with-ik/Dockerfile`，或者直接在 `docs` 目录下临时创建，然后构建）。

    **`Dockerfile` 内容**:
    
    ```dockerfile
    # 使用官方 Elasticsearch 7.17.6 作为基础镜像
    FROM elasticsearch:7.17.6
    
    # 安装 IK 分词器插件（指定版本一致）
    RUN bin/elasticsearch-plugin install --batch https://release.infinilabs.com/analysis-ik/stable/elasticsearch-analysis-ik-7.17.6.zip
    
    # 关闭安全认证 + 启动为单节点
    ENV discovery.type=single-node
    ENV xpack.security.enabled=false
    ENV xpack.ml.enabled=false
    ENV xpack.watcher.enabled=false
    ENV xpack.license.self_generated.type=basic
    
    # 暴露端口
    EXPOSE 9200 9300
    
    # 保持默认的 Elasticsearch 启动命令
    ```
    
    然后，在包含此 `Dockerfile` 的目录下执行构建命令：
    ```sh
    docker build -t elasticsearch-with-ik:7.17.6 .
    ```
    -   `-t elasticsearch-with-ik:8.8.2`: 为自定义镜像打上标签。
    
3.  **启动 Elasticsearch (使用自定义镜像)**:
    ```sh
    docker run -d --name elasticsearch \
      -p 9200:9200 -p 9300:9300 \
      --memory="1g" \
      -v $(pwd)/elasticsearch/data:/usr/share/elasticsearch/data \
      --network doj \
      elasticsearch-with-ik:7.17.6
    ```
    -   `--memory=1g`: 限制 ES 内存使用，避免 OOM。
    -   `-v $(pwd)/elasticsearch/data:/usr/share/elasticsearch/data`: 数据持久化。
    
4.  **启动 Kibana**:
    ```sh
    docker run -d --name kibana -p 5601:5601 \
      -e "ELASTICSEARCH_HOSTS=http://elasticsearch:9200" \
      --network doj \
      kibana:7.17.6
    ```
    -   `ELASTICSEARCH_HOSTS`: 指向 Elasticsearch 服务名和端口。

### 2.3. 部署 RabbitMQ

项目使用 RabbitMQ 实现服务间的异步通信。

```sh
docker run -d \
  --name rabbitmq \
  -p 5672:5672 \
  -p 15672:15672 \
  --hostname my-rabbit \
  --network doj \
  rabbitmq:3-management
```
访问 `http://localhost:15672` 进入管理后台 (默认用户名/密码: `guest`/`guest`)。

### 2.6. 部署 Sentinel (流量治理)

项目使用 Sentinel 进行流量控制和熔断降级。我们需要启动其控制台来进行实时监控和规则配置。

```sh
docker run -d \
  --name sentinel \
  -p 8858:8858 \
  --network doj \
  bladex/sentinel-dashboard
```

**注意**: Sentinel Dashboard 默认端口为 `8080`，与我们的网关冲突。因此，这里将其映射到主机的 `8858` 端口。

部署成功后，访问 `http://localhost:8858` 进入管理后台 (默认用户名/密码: `sentinel`/`sentinel`)。

### 2.7. 部署 Nacos

Nacos 依赖于 MySQL 存储其配置数据，因此需要先初始化 Nacos 的数据库表。

1.  **初始化 Nacos 数据库**：将 ``docs/SQL/`` 中提供的 Nacos SQL 初始化脚本导入到刚刚创建的 `nacos` 数据库中。

2.  **准备 Nacos 环境变量文件**：

    ```sh
    # 创建目录和文件
    mkdir -p nacos
    touch nacos/custom.env
    ```

3.  **获取 MySQL 容器 IP 地址**：Nacos 需要通过 IP 地址连接到 MySQL 容器。

    ```sh
    docker inspect mysql | grep IPAddress
    ```

    记下返回的 IP 地址（例如 `172.18.0.2`）。

4.  **编辑 `nacos/custom.env` 文件**，填入以下内容，并**将 `MYSQL_SERVICE_HOST` 的值替换为您上一步获取到的 IP 地址**。

    ```properties
    PREFER_HOST_MODE=hostname
    MODE=standalone
    SPRING_DATASOURCE_PLATFORM=mysql
    MYSQL_SERVICE_HOST=mysql
    MYSQL_SERVICE_DB_NAME=nacos #是你自己的mysql容器名称
    MYSQL_SERVICE_PORT=3306
    MYSQL_SERVICE_USER=root
    MYSQL_SERVICE_PASSWORD=123
    MYSQL_SERVICE_DB_PARAM=characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&allowPublicKeyRetrieval=true&queryTimeout=2400&serverTimezone=Asia/Shanghai
    ```

5.  **运行 Nacos 容器**：

    ```sh
    docker run -d \
        --name nacos \
        --env-file ./nacos/custom.env \
        -p 8848:8848 \
        -p 9848:9848 \
        -p 9849:9849 \
        --network doj \
        nacos/nacos-server:v2.5.1-slim
    ```

### 2.8. 在 Nacos 中添加共享配置

1.  访问 Nacos 控制台：`http://localhost:8848/nacos` (默认用户名/密码: `nacos`/`nacos`)。
2.  进入 “配置管理” -> “配置列表”，点击右侧“+”号，创建以下三个共享配置文件。请确保 **Data ID** 和 **Group** 正确无误（通常使用默认的 `DEFAULT_GROUP`）。

    -   **Data ID**: `shared-jdbc.yaml`
    -   **内容** (Redis 配置也已集成):
        
        ```yaml
        spring:
          datasource:
            driver-class-name: com.mysql.cj.jdbc.Driver
            url: jdbc:mysql://${doj.db.host:127.0.0.1}:3306/${doj.db.name}
            username: ${doj.db.user:root}
            password: ${doj.db.pwd:123}
          redis:
            host: ${doj.redis.host:127.0.0.1}
            port: 6379
        mybatis-plus:
          global-config:
            db-config:
              update-strategy: not_null
              id-type: auto
        ```
        
    -   **Data ID**: `shared-swagger.yaml`
    -   **内容**:
        ```yaml
        logging:
            level:
                com.decade: debug
        knife4j:
            enable: true
            openapi:
                title: ${doj.swagger.title}
                description: "D-OnlineJudge API"
                version: v1.0.0
                group:
                    default:
                        group-name: default
                        api-rule: package
                        api-rule-resources:
                            - ${doj.swagger.scan}
        ```
    
    -   **Data ID**: `shared-jwt.yaml`
    -   **内容**:
        
        ```yaml
        doj:
            jwt:
                location: classpath:doj.jks
                alias: decade
                password: doj123
                tokenTTL: 30m
                refreshTokenTTL: 7d # 新增
                authorization: "authorization"
                secret-key: "uid"
        ```
    -   **Data ID**: `shared-rabbitmq.yaml`
    -   **内容**:
        
        ```yaml
        spring:
            rabbitmq:
                host: ${doj.mq.host:127.0.0.1}
                port: 5672
                username: guest
                password: guest
        ```

---

## 3. 构建和运行后端微服务

### 3.1. 生成 JWT 密钥库

`common` 模块需要一个 JKS 文件来签名和验证 JWT。在 `DOJ-BE/common/src/main/resources/` 目录下执行以下命令：

```sh
keytool -genkeypair -alias decade -keyalg RSA -keysize 2048 -validity 365 -keypass doj123 -keystore doj.jks -storepass doj123
```

### 3.2. 构建所有模块

在后端父项目 `DOJ-BE` 的根目录下，使用 Maven 进行编译和打包。

```sh
cd /Users/qzj/Desktop/Development/D-OnlineJudge/DOJ-BE
mvn clean install
```

### 3.3. 运行微服务

为每个微服务打开一个单独的终端，并从 `DOJ-BE` 根目录启动它们。建议按照以下顺序启动：

1.  **Gateway-Service**
    ```sh
    java -Dhttp.proxySet=false -Dhttps.proxySet=false -jar gateway-service/target/gateway-service-1.0-SNAPSHOT.jar
    ```
2.  **User-Service**
    ```sh
    java -Dhttp.proxySet=false -Dhttps.proxySet=false -jar user-service/target/user-service-1.0-SNAPSHOT.jar
    ```
3.  **Problem-Service**
    ```sh
    java -Dhttp.proxySet=false -Dhttps.proxySet=false -jar problem-service/target/problem-service-1.0-SNAPSHOT.jar
    ```
4.  **Submission-Service**
    ```sh
    java -Dhttp.proxySet=false -Dhttps.proxySet=false -jar submission-service/target/submission-service-1.0-SNAPSHOT.jar
    ```
5.  **Sandbox-Service**
    ```sh
    java -Dhttp.proxySet=false -Dhttps.proxySet=false -jar sandbox-service/target/sandbox-service-1.0-SNAPSHOT.jar
    ```

### 3.4. 验证服务状态

- **检查 Nacos**: 再次访问 Nacos 控制台 `http://localhost:8848/nacos`，进入 “服务管理” -> “服务列表”，您应该能看到所有已启动的微服务（`gateway-service`, `user-service` 等）都处于健康状态。
- **访问 API 文档**: 访问网关提供的聚合 API 文档 `http://localhost:8080/doc.html`，您应该能看到所有微服务的接口列表。

## 4. 可观测性平台搭建

### 4.1. 部署 SkyWalking (分布式追踪)

项目使用 SkyWalking 进行服务间的链路追踪。我们通过一个独立的 Docker Compose 文件来部署它及其依赖的 Elasticsearch。

1.  **启动 SkyWalking 服务**:
    在项目根目录下，执行以下命令：
    ```sh
    docker-compose -f docker-compose-skywalking.yml up -d
    ```

2.  **访问 SkyWalking UI**:
    等待一到两分钟，让所有服务完全启动。然后，通过浏览器访问 `http://localhost:9999`。

### 4.2. 部署 Prometheus + Grafana (指标监控)

我们使用 Prometheus 抓取指标，Grafana 进行可视化展示。

1.  **启动监控服务**:
    在项目根目录下，执行以下命令：
    ```sh
    docker-compose -f docker-compose-monitoring.yml up -d
    ```

2.  **访问 Grafana UI**:
    通过浏览器访问 `http://localhost:3000` (默认用户名/密码: `admin`/`admin`)。

3.  **配置数据源与仪表盘**:
    在 Grafana 中，添加 Prometheus (`http://prometheus:9090`) 作为数据源，然后即可创建或导入仪表盘来展示微服务指标。

4.  **导入预置仪表盘 (推荐)**:
    为了快速开始，项目根目录下提供了一个预置的仪表盘文件 `grafana-dashboard.json`。
    - 在 Grafana 左侧菜单，点击 “+” -> “Import dashboard”。
    - 点击 “Upload JSON file”，选择项目中的 `grafana-dashboard.json` 文件。
    - 在下方的 “Prometheus” 选项中，选择您刚刚配置好的 Prometheus 数据源。
    - 点击 “Import”，即可拥有一个包含所有核心指标的监控大盘。

### 4.3. 部署 Loki (日志聚合)

我们使用 Loki 聚合所有微服务的日志，并由 Promtail 进行采集。

1.  **启动日志服务**:
    Loki 和 Promtail 的配置已包含在 `docker-compose-monitoring.yml` 中。执行以下命令即可一并启动：
    ```sh
    docker-compose -f docker-compose-monitoring.yml up -d
    ```

2.  **在 Grafana 中添加 Loki 数据源**:
    - 访问 Grafana (`http://localhost:3000`)。
    - 进入 "Configuration" -> "Data sources"，点击 "Add data source"。
    - 选择 "Loki"。
    - 在 URL 字段中，输入 `http://loki:3100`。
    - 点击 "Save & test"。

3.  **查询日志**:
    添加成功后，即可在 Grafana 的 "Explore" 页面选择 Loki 数据源，并通过容器名称等标签来查询日志。

### 4.4. 为微服务挂载 Agent (IntelliJ IDEA)

为了让微服务能被 SkyWalking 追踪，需要在启动时为其挂载 Agent 探针。

1.  **修改运行配置**: 在 IntelliJ IDEA 中，为每一个后端微服务（`user-service`, `gateway-service` 等）的“运行/调试配置” (Run/Debug Configurations) 进行修改。
2.  **添加 VM 选项**: 找到 "VM options" 输入框，并添加以下两行：
    ```
    -javaagent:/path/to/your/skywalking-agent/skywalking-agent.jar
    -Dskywalking.agent.service_name=user-service
    ```
    - **注意**: 
        - 将 `/path/to/your/skywalking-agent/` 替换为您本地 `skywalking-agent` 文件夹的**绝对路径**。
        - `-Dskywalking.agent.service_name` 的值需要为每个服务单独设置（如 `problem-service`, `gateway-service` 等）。

3.  **重启所有服务**后，即可在 SkyWalking UI 上看到服务拓扑和调用链路。

---

## 5. 代码沙箱 Docker 环境

`sandbox-service` 依赖于预先构建好的 Docker 镜像来执行代码。请确保您已经构建了项目所需的多语言执行环境镜像。

进入 `docs/7.Sandbox-service项目配置.md` 文件所在的目录，您会找到 `Dockerfile.cpp`, `Dockerfile.java`, `Dockerfile.python` 等文件。

使用以下命令构建镜像：

```sh
# 构建 C++ 环境镜像
docker build -t code-runner-cpp -f Dockerfile.cpp .

# 构建 Java 环境镜像
docker build -t code-runner-java -f Dockerfile.java .

# 构建 Python 环境镜像
docker build -t code-runner-python -f Dockerfile.python .
```

确保这些镜像在 `sandbox-service` 运行的 Docker 环境中是可用的。

---

## 5. 自动化部署 (CI/CD)

除了手动部署，本项目已配置了一套基于 GitHub Actions 的自动化 CI/CD 流水线。当代码被推送到 `main` 分支时，会自动触发以下流程：

1.  **并行构建**: 自动编译所有微服务，并使用各自的 `Dockerfile` 构建 Docker 镜像。
2.  **推送镜像**: 将构建好的镜像推送到 Docker Hub。
3.  **远程部署**: 通过 SSH 连接到服务器，拉取最新镜像并使用 `docker-compose` 重启服务。

### 准备工作

### 核心环境变量说明

本项目的容器化部署高度依赖环境变量来实现配置的灵活性。以下是在 `docker-compose-service.yml` 中使用的核心变量及其作用：

-   **`NACOS_SERVER_ADDR`**: Nacos 服务器地址，容器环境应设为 `nacos:8848`。
-   **`SENTINEL_DASHBOARD_ADDR`**: Sentinel Dashboard 地址，容器环境应设为 `sentinel:8080`。
-   **`DOJ_DB_HOST`**: 数据库主机地址，容器环境应设为 `mysql`。
-   **`DOJ_MQ_HOST`**: RabbitMQ 主机地址，容器环境应设为 `rabbitmq`。
-   **`DOJ_REDIS_HOST`**: Redis 主机地址，容器环境应设为 `redis`。
-   **`HOST_CODE_PATH`**: (仅用于 `sandbox-service`) 宿主机上用于存放临时代码的目录的绝对路径。通过 `${PWD}/static/codes` 动态获取，用于解决 Docker-out-of-Docker 的路径挂载问题。
-   **`JAVA_OPTS`**: 用于设置 JVM 启动参数，如 `-Xms128m -Xmx256m`，以控制服务内存占用。

核心配置文件位于 `.github/workflows/ci-cd.yml`。

## 6. 前端部署 (Docker + Nginx)

前端项目 (`DOJ-FE`) 采用业界标准的“打包 + Nginx 托管”的方式进行容器化部署。

### 6.1. 环境与配置

在部署前，请确保已完成以下配置，以保证前后端通信正常：

1.  **环境变量**: 项目通过 `.env.development` 和 `.env.production` 文件来管理不同环境的 API 地址。我们已将其统一为相对路径 `/api`。

2.  **Vite 代理 (仅开发环境)**: 在 `vite.config.ts` 中配置了 `server.proxy`，使得在开发模式下，所有对 `/api` 的请求都会被代理到本地运行的后端网关 (`http://localhost:8080`)。

3.  **Nginx 代理 (生产环境)**: 在 `DOJ-FE/nginx.conf` 文件中，配置了反向代理规则。所有 `/api` 请求会被转发到 `http://host.docker.internal:8080/`，即宿主机上运行的后端网关服务。这使得容器化的前端可以与本地运行的后端进行通信。

### 6.2. 一键部署脚本

为了简化部署流程，项目在 `DOJ-FE` 目录下提供了一个一键部署脚本 `run-docker.sh`。

**使用方法:**

1.  **进入前端项目目录**:
    ```sh
    cd /Users/qzj/Desktop/Development/D-OnlineJudge/DOJ-FE
    ```

2.  **为脚本添加执行权限 (仅需一次)**:
    ```sh
    chmod +x run-docker.sh
    ```

3.  **执行一键部署**:
    ```sh
    ./run-docker.sh
    ```

该脚本会自动完成以下所有工作：
- **打包应用**: 执行 `pnpm build` 生成最新的静态文件到 `dist` 目录。
- **构建镜像**: 执行 `docker build`，根据 `Dockerfile` 将 `dist` 目录和 `nginx.conf` 打包成一个名为 `doj-frontend` 的 Nginx 镜像。
- **清理旧容器**: 自动停止并删除任何已存在的同名旧容器。
- **启动新容器**: 启动一个新的容器，并将主机的 `8088` 端口映射到容器的 `80` 端口。

部署成功后，即可通过浏览器访问 `http://localhost:8088` 来使用 D-OnlineJudge 系统。

